{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.1 층: 딥러닝의 구성 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.15.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.9)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차원이 784인 2D 텐서만 입력으로 받는 층. 출력은 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Dense(32, input_shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input 784 => 1st layer : 32-dim => 2st layer : 10\n",
    "- sequential() 을 사용할 것\n",
    "\n",
    "- 참고 : layer에서 input size를 넣지 않는다면 자동으로 상위층의 size를 인식함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784, )) )\n",
    "model.add(layers.Dense(10))  # 상위층의 size를 자동으로 인식. model.add(layers.Dense(10, input_shape=(32, )) ) 과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전형적인 케라스 작업 흐름\n",
    "1. input tensor와 target tensor로 이루어진 training data를 정의.\n",
    "2. input과 target을 매핑하는 층으로 이루어진 network(또는 model)을 정의\n",
    "3. loss function, optimizer, 모니터링하기 위한 측정지표를 선택하여 학습 과정을 설정\n",
    "4. training data에 대해 model의 fit() 메서드를 반복적으로 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model을 정의하는 방법\n",
    "- sequential class\n",
    "- functional API (7장에서 자세히 다룸)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential class\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(784, )) )\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functinal api"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# functional API\n",
    "input_tensor = layers.Input(shape=(784,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "(60000, 784)\n",
      "(10000, 784)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1805 - acc: 0.0973\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1805 - acc: 0.0975\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1762 - acc: 0.1186\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1600 - acc: 0.1997\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.1601 - acc: 0.1993\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1592 - acc: 0.2037\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1594 - acc: 0.2029\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1596 - acc: 0.2021\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1593 - acc: 0.2034\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1594 - acc: 0.2030\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1593 - acc: 0.2036\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1590 - acc: 0.2049\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1590 - acc: 0.2049\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1589 - acc: 0.2056\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1590 - acc: 0.2051\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1591 - acc: 0.2045\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1595 - acc: 0.2022\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1588 - acc: 0.2059\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1587 - acc: 0.2064\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1589 - acc: 0.2054\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1587 - acc: 0.2064\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1591 - acc: 0.2046\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1588 - acc: 0.2058\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1597 - acc: 0.2016\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1618 - acc: 0.1907\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1591 - acc: 0.2043\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1590 - acc: 0.2046\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1588 - acc: 0.2059\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1605 - acc: 0.1974\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1642 - acc: 0.1788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b79eb9160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# get data\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# reshape\n",
    "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1]*train_images.shape[2])\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1]*test_images.shape[2])\n",
    "\n",
    "# ready to categorical value (label)\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "#training\n",
    "model.fit(train_images, train_labels, batch_size=128, epochs=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "(ttrain_images, ttrain_labels), (ttest_images, ttest_labels) = mnist.load_data()\n",
    "ttrain_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test2\n",
    "ttrain_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test3\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## practice - Please make Network and input the hyper parameter for yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shape]\n",
      "train_images: (60000, 28, 28) \n",
      "train_labels: (60000,) \n",
      "test_images: (10000, 28, 28) \n",
      "test_labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"[shape]\")\n",
    "print(\"train_images:\", train_images.shape, \"\\ntrain_labels:\", train_labels.shape, \"\\ntest_images:\", test_images.shape, \"\\ntest_labels:\", test_labels.shape)\n",
    "\n",
    "# reshape images\n",
    "\n",
    "\n",
    "# convert to categorical value (for label)\n",
    "\n",
    "\n",
    "# decision Model(or Network)\n",
    "## recommend function : Sequential()\n",
    "## please make 2-layer (include output layer)\n",
    "\n",
    "\n",
    "# compile Model(or Network)\n",
    "## please input the hyperparameter ( optimizer, leaning rate, loss, metric... )\n",
    "\n",
    "#training\n",
    "\n",
    "\n",
    "# *Suggest network and hyperparameter aggressively.  DeepLearning is Practical studies!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1] * train_images.shape[2])\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1] * test_images.shape[2])\n",
    "\n",
    "\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.9226 - acc: 0.8288\n",
      "Epoch 2/5\n",
      "20736/60000 [=========>....................] - ETA: 1s - loss: 0.5139 - acc: 0.9237"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-74a88f7dc37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#m.fit(train_images, train_labels, batch_size=128, epochs=30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "m = models.Sequential()\n",
    "#m.add(layers.Conv2D(2, (3,3), padding='valid', activation='relu', input_shape=(60000, 28, 28)))\n",
    "#m.add(layers.Dense(32, activation=\"relu\", input_shape=(784, )))\n",
    "m.add(layers.Dense(32, activation=\"relu\", input_shape=(784, )))\n",
    "m.add(layers.Dense(24, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01) ))\n",
    "m.add(layers.Dense(16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "m.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "#m.compile(optimizer=optimizers.RMSprop(lr=0.001),loss='mse',metrics=['accuracy'] )\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#m.fit(train_images, train_labels, batch_size=128, epochs=30)\n",
    "\n",
    "m.fit(train_images, train_labels, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shape]\n",
      "train_images: (60000, 28, 28) \n",
      "train_labels: (60000,) \n",
      "test_images: (10000, 28, 28) \n",
      "test_labels: (10000,)\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2583 - acc: 0.9255\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1037 - acc: 0.9691\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0676 - acc: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0495 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0365 - acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b78474978>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# get data\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"[shape]\")\n",
    "print(\"train_images:\", train_images.shape, \"\\ntrain_labels:\", train_labels.shape, \"\\ntest_images:\", test_images.shape, \"\\ntest_labels:\", test_labels.shape)\n",
    "\n",
    "# reshape images\n",
    "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1]*train_images.shape[2])\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1]*test_images.shape[2])\n",
    "\n",
    "# uint8 to float32 - to efficiency learning\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "# convert to categorical value (for label)\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "# decision Model(or Network)\n",
    "## recommend function : Sequential()\n",
    "## please make 2-layer (include output layer)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(784, )) )\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# compile Model(or Network)\n",
    "## please input the hyperparameter ( optimizer, leaning rate, loss, metric... )\n",
    "from keras import optimizers\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "#               loss='mse',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'] )\n",
    "\n",
    "#training\n",
    "model.fit(train_images, train_labels, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
